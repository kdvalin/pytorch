
// WARNING: THIS FILE IS AUTOGENERATED BY torchgen. DO NOT MODIFY BY HAND.

#include <torch/csrc/inductor/aoti_torch/generated/c_shim_cuda.h>
#include <torch/csrc/inductor/aoti_torch/utils.h>

#ifndef AT_PER_OPERATOR_HEADERS
#include <ATen/CUDAFunctions.h>
#include <ATen/CompositeExplicitAutogradFunctions.h>
#include <ATen/CompositeExplicitAutogradNonFunctionalFunctions.h>
#else
#include <ATen/ops/_adaptive_avg_pool2d_backward_cuda_dispatch.h>
#include <ATen/ops/_adaptive_avg_pool2d_cuda_dispatch.h>
#include <ATen/ops/_adaptive_avg_pool3d_backward_cuda_dispatch.h>
#include <ATen/ops/_adaptive_avg_pool3d_cuda_dispatch.h>
#include <ATen/ops/_addmm_activation_cuda_dispatch.h>
#include <ATen/ops/_cdist_backward_cuda_dispatch.h>
#include <ATen/ops/_cdist_forward_cuda_dispatch.h>
#include <ATen/ops/_cudnn_rnn_backward_cuda_dispatch.h>
#include <ATen/ops/_cudnn_rnn_cuda_dispatch.h>
#include <ATen/ops/_efficient_attention_backward_cuda_dispatch.h>
#include <ATen/ops/_efficient_attention_forward_cuda_dispatch.h>
#include <ATen/ops/_efficientzerotensor_cuda_dispatch.h>
#include <ATen/ops/_embedding_bag_cuda_dispatch.h>
#include <ATen/ops/_embedding_bag_dense_backward_cuda_dispatch.h>
#include <ATen/ops/_embedding_bag_forward_only_cuda_dispatch.h>
#include <ATen/ops/_embedding_bag_per_sample_weights_backward_cuda_dispatch.h>
#include <ATen/ops/_fft_c2c_cuda_dispatch.h>
#include <ATen/ops/_fft_r2c_cuda_dispatch.h>
#include <ATen/ops/_flash_attention_backward_cuda_dispatch.h>
#include <ATen/ops/_flash_attention_forward_cuda_dispatch.h>
#include <ATen/ops/_fused_moving_avg_obs_fq_helper_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/_fused_moving_avg_obs_fq_helper_cuda_dispatch.h>
#include <ATen/ops/_linalg_check_errors_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/_linalg_det_cuda_dispatch.h>
#include <ATen/ops/_linalg_eigh_cuda_dispatch.h>
#include <ATen/ops/_linalg_slogdet_cuda_dispatch.h>
#include <ATen/ops/_linalg_solve_ex_cuda_dispatch.h>
#include <ATen/ops/_linalg_svd_cuda_dispatch.h>
#include <ATen/ops/_pdist_backward_cuda_dispatch.h>
#include <ATen/ops/_pdist_forward_cuda_dispatch.h>
#include <ATen/ops/_scaled_dot_product_efficient_attention_backward_cuda_dispatch.h>
#include <ATen/ops/_scaled_dot_product_efficient_attention_cuda_dispatch.h>
#include <ATen/ops/_scaled_dot_product_flash_attention_backward_cuda_dispatch.h>
#include <ATen/ops/_scaled_dot_product_flash_attention_cuda_dispatch.h>
#include <ATen/ops/_scaled_mm_cuda_dispatch.h>
#include <ATen/ops/_segment_reduce_backward_cuda_dispatch.h>
#include <ATen/ops/_thnn_fused_lstm_cell_cuda_dispatch.h>
#include <ATen/ops/_to_sparse_cuda_dispatch.h>
#include <ATen/ops/_trilinear_compositeexplicitautogradnonfunctional_dispatch.h>
#include <ATen/ops/adaptive_max_pool2d_backward_cuda_dispatch.h>
#include <ATen/ops/adaptive_max_pool2d_cuda_dispatch.h>
#include <ATen/ops/adaptive_max_pool3d_backward_cuda_dispatch.h>
#include <ATen/ops/adaptive_max_pool3d_cuda_dispatch.h>
#include <ATen/ops/addbmm_cuda_dispatch.h>
#include <ATen/ops/addmm_cuda_dispatch.h>
#include <ATen/ops/addmv_cuda_dispatch.h>
#include <ATen/ops/angle_cuda_dispatch.h>
#include <ATen/ops/avg_pool2d_backward_cuda_dispatch.h>
#include <ATen/ops/avg_pool2d_cuda_dispatch.h>
#include <ATen/ops/avg_pool3d_backward_cuda_dispatch.h>
#include <ATen/ops/avg_pool3d_cuda_dispatch.h>
#include <ATen/ops/bmm_cuda_dispatch.h>
#include <ATen/ops/bucketize_cuda_dispatch.h>
#include <ATen/ops/cat_cuda_dispatch.h>
#include <ATen/ops/cholesky_inverse_cuda_dispatch.h>
#include <ATen/ops/cholesky_solve_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/convolution_backward_cuda_dispatch.h>
#include <ATen/ops/convolution_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/cummax_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/cummin_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/cumprod_cuda_dispatch.h>
#include <ATen/ops/cumsum_cuda_dispatch.h>
#include <ATen/ops/exponential_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/fractional_max_pool2d_backward_cuda_dispatch.h>
#include <ATen/ops/fractional_max_pool2d_cuda_dispatch.h>
#include <ATen/ops/fractional_max_pool3d_backward_cuda_dispatch.h>
#include <ATen/ops/fractional_max_pool3d_cuda_dispatch.h>
#include <ATen/ops/gcd_cuda_dispatch.h>
#include <ATen/ops/geqrf_cuda_dispatch.h>
#include <ATen/ops/grid_sampler_2d_backward_cuda_dispatch.h>
#include <ATen/ops/histc_cuda_dispatch.h>
#include <ATen/ops/index_reduce_cuda_dispatch.h>
#include <ATen/ops/kthvalue_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/linalg_cholesky_ex_cuda_dispatch.h>
#include <ATen/ops/linalg_householder_product_cuda_dispatch.h>
#include <ATen/ops/linalg_inv_ex_cuda_dispatch.h>
#include <ATen/ops/linalg_ldl_factor_ex_cuda_dispatch.h>
#include <ATen/ops/linalg_ldl_solve_cuda_dispatch.h>
#include <ATen/ops/linalg_lu_cuda_dispatch.h>
#include <ATen/ops/linalg_lu_factor_ex_cuda_dispatch.h>
#include <ATen/ops/linalg_lu_solve_cuda_dispatch.h>
#include <ATen/ops/linalg_matrix_exp_cuda_dispatch.h>
#include <ATen/ops/linalg_pinv_compositeexplicitautogradnonfunctional_dispatch.h>
#include <ATen/ops/linalg_qr_cuda_dispatch.h>
#include <ATen/ops/linalg_solve_triangular_cuda_dispatch.h>
#include <ATen/ops/logcumsumexp_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/lu_unpack_cuda_dispatch.h>
#include <ATen/ops/masked_scatter_backward_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/masked_scatter_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/max_pool2d_with_indices_backward_cuda_dispatch.h>
#include <ATen/ops/max_pool2d_with_indices_cuda_dispatch.h>
#include <ATen/ops/max_pool3d_with_indices_backward_cuda_dispatch.h>
#include <ATen/ops/max_pool3d_with_indices_cuda_dispatch.h>
#include <ATen/ops/max_unpool2d_cuda_dispatch.h>
#include <ATen/ops/max_unpool3d_cuda_dispatch.h>
#include <ATen/ops/median_cuda_dispatch.h>
#include <ATen/ops/mm_cuda_dispatch.h>
#include <ATen/ops/mode_cuda_dispatch.h>
#include <ATen/ops/mul_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/nanmedian_cuda_dispatch.h>
#include <ATen/ops/nonzero_cuda_dispatch.h>
#include <ATen/ops/ormqr_cuda_dispatch.h>
#include <ATen/ops/rand_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/randint_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/randn_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/randperm_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/repeat_interleave_cuda_dispatch.h>
#include <ATen/ops/replication_pad1d_backward_cuda_dispatch.h>
#include <ATen/ops/replication_pad2d_backward_cuda_dispatch.h>
#include <ATen/ops/resize_as_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/resize_cuda_dispatch.h>
#include <ATen/ops/scatter_cuda_dispatch.h>
#include <ATen/ops/scatter_reduce_cuda_dispatch.h>
#include <ATen/ops/segment_reduce_cuda_dispatch.h>
#include <ATen/ops/soft_margin_loss_backward_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/sort_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/topk_cuda_dispatch.h>
#include <ATen/ops/triangular_solve_cuda_dispatch.h>
#include <ATen/ops/uniform_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/upsample_bicubic2d_backward_cuda_dispatch.h>
#include <ATen/ops/upsample_linear1d_backward_cuda_dispatch.h>
#include <ATen/ops/upsample_trilinear3d_backward_cuda_dispatch.h>
#include <ATen/ops/view_as_complex_cuda_dispatch.h>
#include <ATen/ops/view_as_real_cuda_dispatch.h>
#include <ATen/ops/view_compositeexplicitautograd_dispatch.h>
#include <ATen/ops/zeros_compositeexplicitautograd_dispatch.h>
#include <c10/cuda/CUDAGuard.h>
#include <ATen/cuda/ATenCUDAGeneral.h>
#include <ATen/cuda/CUDADevice.h>
#include <ATen/cuda/CUDAContext.h>
#endif

using namespace torch::aot_inductor;


AOTITorchError aoti_torch_cuda__adaptive_avg_pool2d(AtenTensorHandle self, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_adaptive_avg_pool2d_symint(
            *tensor_handle_to_tensor_pointer(self), pointer_to_list<c10::SymInt>(output_size, output_size_len_)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__adaptive_avg_pool2d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_adaptive_avg_pool2d_backward(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(self)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__adaptive_avg_pool3d(AtenTensorHandle self, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_adaptive_avg_pool3d_symint(
            *tensor_handle_to_tensor_pointer(self), pointer_to_list<c10::SymInt>(output_size, output_size_len_)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__adaptive_avg_pool3d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_adaptive_avg_pool3d_backward(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(self)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__addmm_activation(AtenTensorHandle self, AtenTensorHandle mat1, AtenTensorHandle mat2, double beta, double alpha, int32_t use_gelu, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_addmm_activation(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(mat1), *tensor_handle_to_tensor_pointer(mat2), beta, alpha, use_gelu
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__cdist_backward(AtenTensorHandle grad, AtenTensorHandle x1, AtenTensorHandle x2, double p, AtenTensorHandle cdist, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_cdist_backward(
            *tensor_handle_to_tensor_pointer(grad), *tensor_handle_to_tensor_pointer(x1), *tensor_handle_to_tensor_pointer(x2), p, *tensor_handle_to_tensor_pointer(cdist)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__cdist_forward(AtenTensorHandle x1, AtenTensorHandle x2, double p, int64_t* compute_mode, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_cdist_forward(
            *tensor_handle_to_tensor_pointer(x1), *tensor_handle_to_tensor_pointer(x2), p, pointer_to_optional<int64_t>(compute_mode)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__cudnn_rnn(AtenTensorHandle input, const AtenTensorHandle* weight, int64_t weight_len_, int64_t weight_stride0, AtenTensorHandle* weight_buf, AtenTensorHandle hx, AtenTensorHandle* cx, int64_t mode, int64_t hidden_size, int64_t proj_size, int64_t num_layers, int32_t batch_first, double dropout, int32_t train, int32_t bidirectional, const int64_t* batch_sizes, int64_t batch_sizes_len_, AtenTensorHandle* dropout_state, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3, AtenTensorHandle* ret4) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_cudnn_rnn_symint(
            *tensor_handle_to_tensor_pointer(input), pointer_to_list<at::Tensor>(weight, weight_len_), weight_stride0, pointer_to_optional<at::Tensor>(weight_buf), *tensor_handle_to_tensor_pointer(hx), pointer_to_optional<at::Tensor>(cx), mode, hidden_size, proj_size, num_layers, batch_first, dropout, train, bidirectional, pointer_to_list<c10::SymInt>(batch_sizes, batch_sizes_len_), pointer_to_optional<at::Tensor>(dropout_state)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
        *ret3 = new_tensor_handle(std::move(std::get<3>(tmp_result)));;
        *ret4 = new_tensor_handle(std::move(std::get<4>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__efficient_attention_backward(AtenTensorHandle grad_out_, AtenTensorHandle query, AtenTensorHandle key, AtenTensorHandle value, AtenTensorHandle* bias, AtenTensorHandle out, AtenTensorHandle* cu_seqlens_q, AtenTensorHandle* cu_seqlens_k, int64_t max_seqlen_q, int64_t max_seqlen_k, AtenTensorHandle logsumexp, double dropout_p, AtenTensorHandle philox_seed, AtenTensorHandle philox_offset, int64_t custom_mask_type, int32_t bias_requires_grad, double* scale, int64_t* num_splits_key, int64_t* window_size, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_efficient_attention_backward_symint(
            *tensor_handle_to_tensor_pointer(grad_out_), *tensor_handle_to_tensor_pointer(query), *tensor_handle_to_tensor_pointer(key), *tensor_handle_to_tensor_pointer(value), pointer_to_optional<at::Tensor>(bias), *tensor_handle_to_tensor_pointer(out), pointer_to_optional<at::Tensor>(cu_seqlens_q), pointer_to_optional<at::Tensor>(cu_seqlens_k), max_seqlen_q, max_seqlen_k, *tensor_handle_to_tensor_pointer(logsumexp), dropout_p, *tensor_handle_to_tensor_pointer(philox_seed), *tensor_handle_to_tensor_pointer(philox_offset), custom_mask_type, bias_requires_grad, pointer_to_optional<double>(scale), pointer_to_optional<int64_t>(num_splits_key), pointer_to_optional<int64_t>(window_size)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
        *ret3 = new_tensor_handle(std::move(std::get<3>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__efficient_attention_forward(AtenTensorHandle query, AtenTensorHandle key, AtenTensorHandle value, AtenTensorHandle* bias, AtenTensorHandle* cu_seqlens_q, AtenTensorHandle* cu_seqlens_k, int64_t* max_seqlen_q, int64_t* max_seqlen_k, double dropout_p, int64_t custom_mask_type, int32_t compute_log_sumexp, double* scale, AtenTensorHandle* causal_diagonal, AtenTensorHandle* seqlen_k, int64_t* window_size, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3, int64_t* ret4, int64_t* ret5) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_efficient_attention_forward(
            *tensor_handle_to_tensor_pointer(query), *tensor_handle_to_tensor_pointer(key), *tensor_handle_to_tensor_pointer(value), pointer_to_optional<at::Tensor>(bias), pointer_to_optional<at::Tensor>(cu_seqlens_q), pointer_to_optional<at::Tensor>(cu_seqlens_k), pointer_to_optional<int64_t>(max_seqlen_q), pointer_to_optional<int64_t>(max_seqlen_k), dropout_p, custom_mask_type, compute_log_sumexp, pointer_to_optional<double>(scale), pointer_to_optional<at::Tensor>(causal_diagonal), pointer_to_optional<at::Tensor>(seqlen_k), pointer_to_optional<int64_t>(window_size)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
        *ret3 = new_tensor_handle(std::move(std::get<3>(tmp_result)));;
        *ret4 = std::get<4>(tmp_result).expect_int();
        *ret5 = std::get<5>(tmp_result).expect_int();
    });
}


AOTITorchError aoti_torch_cuda__efficientzerotensor(const int64_t* size, int64_t size_len_, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_efficientzerotensor_symint(
            pointer_to_list<c10::SymInt>(size, size_len_), pointer_to_optional<c10::ScalarType>(dtype), pointer_to_optional<c10::Layout>(layout), pointer_to_optional_device(device, device_index_), pointer_to_optional<bool>(pin_memory)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__embedding_bag(AtenTensorHandle weight, AtenTensorHandle indices, AtenTensorHandle offsets, int32_t scale_grad_by_freq, int64_t mode, int32_t sparse, AtenTensorHandle* per_sample_weights, int32_t include_last_offset, int64_t padding_idx, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_embedding_bag(
            *tensor_handle_to_tensor_pointer(weight), *tensor_handle_to_tensor_pointer(indices), *tensor_handle_to_tensor_pointer(offsets), scale_grad_by_freq, mode, sparse, pointer_to_optional<at::Tensor>(per_sample_weights), include_last_offset, padding_idx
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
        *ret3 = new_tensor_handle(std::move(std::get<3>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__embedding_bag_dense_backward(AtenTensorHandle grad, AtenTensorHandle indices, AtenTensorHandle offset2bag, AtenTensorHandle bag_size, AtenTensorHandle maximum_indices, int64_t num_weights, int32_t scale_grad_by_freq, int64_t mode, AtenTensorHandle* per_sample_weights, int64_t padding_idx, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_embedding_bag_dense_backward_symint(
            *tensor_handle_to_tensor_pointer(grad), *tensor_handle_to_tensor_pointer(indices), *tensor_handle_to_tensor_pointer(offset2bag), *tensor_handle_to_tensor_pointer(bag_size), *tensor_handle_to_tensor_pointer(maximum_indices), num_weights, scale_grad_by_freq, mode, pointer_to_optional<at::Tensor>(per_sample_weights), padding_idx
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__embedding_bag_forward_only(AtenTensorHandle weight, AtenTensorHandle indices, AtenTensorHandle offsets, int32_t scale_grad_by_freq, int64_t mode, int32_t sparse, AtenTensorHandle* per_sample_weights, int32_t include_last_offset, int64_t padding_idx, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_embedding_bag_forward_only(
            *tensor_handle_to_tensor_pointer(weight), *tensor_handle_to_tensor_pointer(indices), *tensor_handle_to_tensor_pointer(offsets), scale_grad_by_freq, mode, sparse, pointer_to_optional<at::Tensor>(per_sample_weights), include_last_offset, padding_idx
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
        *ret3 = new_tensor_handle(std::move(std::get<3>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__embedding_bag_per_sample_weights_backward(AtenTensorHandle grad, AtenTensorHandle weight, AtenTensorHandle indices, AtenTensorHandle offsets, AtenTensorHandle offset2bag, int64_t mode, int64_t padding_idx, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_embedding_bag_per_sample_weights_backward(
            *tensor_handle_to_tensor_pointer(grad), *tensor_handle_to_tensor_pointer(weight), *tensor_handle_to_tensor_pointer(indices), *tensor_handle_to_tensor_pointer(offsets), *tensor_handle_to_tensor_pointer(offset2bag), mode, padding_idx
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__fft_c2c(AtenTensorHandle self, const int64_t* dim, int64_t dim_len_, int64_t normalization, int32_t forward, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_fft_c2c_symint(
            *tensor_handle_to_tensor_pointer(self), pointer_to_list<c10::SymInt>(dim, dim_len_), normalization, forward
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__fft_r2c(AtenTensorHandle self, const int64_t* dim, int64_t dim_len_, int64_t normalization, int32_t onesided, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_fft_r2c(
            *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(dim, dim_len_), normalization, onesided
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__flash_attention_backward(AtenTensorHandle grad_out, AtenTensorHandle query, AtenTensorHandle key, AtenTensorHandle value, AtenTensorHandle out, AtenTensorHandle logsumexp, AtenTensorHandle cum_seq_q, AtenTensorHandle cum_seq_k, int64_t max_q, int64_t max_k, double dropout_p, int32_t is_causal, AtenTensorHandle philox_seed, AtenTensorHandle philox_offset, double* scale, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_flash_attention_backward_symint(
            *tensor_handle_to_tensor_pointer(grad_out), *tensor_handle_to_tensor_pointer(query), *tensor_handle_to_tensor_pointer(key), *tensor_handle_to_tensor_pointer(value), *tensor_handle_to_tensor_pointer(out), *tensor_handle_to_tensor_pointer(logsumexp), *tensor_handle_to_tensor_pointer(cum_seq_q), *tensor_handle_to_tensor_pointer(cum_seq_k), max_q, max_k, dropout_p, is_causal, *tensor_handle_to_tensor_pointer(philox_seed), *tensor_handle_to_tensor_pointer(philox_offset), pointer_to_optional<double>(scale)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__flash_attention_forward(AtenTensorHandle query, AtenTensorHandle key, AtenTensorHandle value, AtenTensorHandle* cum_seq_q, AtenTensorHandle* cum_seq_k, int64_t max_q, int64_t max_k, double dropout_p, int32_t is_causal, int32_t return_debug_mask, double* scale, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3, AtenTensorHandle* ret4) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_flash_attention_forward_symint(
            *tensor_handle_to_tensor_pointer(query), *tensor_handle_to_tensor_pointer(key), *tensor_handle_to_tensor_pointer(value), pointer_to_optional<at::Tensor>(cum_seq_q), pointer_to_optional<at::Tensor>(cum_seq_k), max_q, max_k, dropout_p, is_causal, return_debug_mask, pointer_to_optional<double>(scale)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
        *ret3 = new_tensor_handle(std::move(std::get<3>(tmp_result)));;
        *ret4 = new_tensor_handle(std::move(std::get<4>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__fused_moving_avg_obs_fq_helper(AtenTensorHandle self, AtenTensorHandle observer_on, AtenTensorHandle fake_quant_on, AtenTensorHandle running_min, AtenTensorHandle running_max, AtenTensorHandle scale, AtenTensorHandle zero_point, double averaging_const, int64_t quant_min, int64_t quant_max, int64_t ch_axis, int32_t per_row_fake_quant, int32_t symmetric_quant, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_fused_moving_avg_obs_fq_helper(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(observer_on), *tensor_handle_to_tensor_pointer(fake_quant_on), *tensor_handle_to_tensor_pointer(running_min), *tensor_handle_to_tensor_pointer(running_max), *tensor_handle_to_tensor_pointer(scale), *tensor_handle_to_tensor_pointer(zero_point), averaging_const, quant_min, quant_max, ch_axis, per_row_fake_quant, symmetric_quant
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__fused_moving_avg_obs_fq_helper_functional(AtenTensorHandle self, AtenTensorHandle observer_on, AtenTensorHandle fake_quant_on, AtenTensorHandle running_min, AtenTensorHandle running_max, AtenTensorHandle scale, AtenTensorHandle zero_point, double averaging_const, int64_t quant_min, int64_t quant_max, int64_t ch_axis, int32_t per_row_fake_quant, int32_t symmetric_quant, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3, AtenTensorHandle* ret4, AtenTensorHandle* ret5) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::_fused_moving_avg_obs_fq_helper_functional(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(observer_on), *tensor_handle_to_tensor_pointer(fake_quant_on), *tensor_handle_to_tensor_pointer(running_min), *tensor_handle_to_tensor_pointer(running_max), *tensor_handle_to_tensor_pointer(scale), *tensor_handle_to_tensor_pointer(zero_point), averaging_const, quant_min, quant_max, ch_axis, per_row_fake_quant, symmetric_quant
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
        *ret3 = new_tensor_handle(std::move(std::get<3>(tmp_result)));;
        *ret4 = new_tensor_handle(std::move(std::get<4>(tmp_result)));;
        *ret5 = new_tensor_handle(std::move(std::get<5>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__linalg_check_errors(AtenTensorHandle info, const char* api_name, int32_t is_matrix) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        at::compositeexplicitautograd::_linalg_check_errors(
            *tensor_handle_to_tensor_pointer(info), api_name, is_matrix
        );
    });
}


AOTITorchError aoti_torch_cuda__linalg_det(AtenTensorHandle A, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_linalg_det(
            *tensor_handle_to_tensor_pointer(A)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__linalg_eigh(AtenTensorHandle A, const char* UPLO, int32_t compute_v, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_linalg_eigh(
            *tensor_handle_to_tensor_pointer(A), UPLO, compute_v
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__linalg_slogdet(AtenTensorHandle A, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_linalg_slogdet(
            *tensor_handle_to_tensor_pointer(A)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
        *ret3 = new_tensor_handle(std::move(std::get<3>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__linalg_solve_ex(AtenTensorHandle A, AtenTensorHandle B, int32_t left, int32_t check_errors, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_linalg_solve_ex(
            *tensor_handle_to_tensor_pointer(A), *tensor_handle_to_tensor_pointer(B), left, check_errors
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
        *ret3 = new_tensor_handle(std::move(std::get<3>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__linalg_svd(AtenTensorHandle A, int32_t full_matrices, int32_t compute_uv, const char** driver, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_linalg_svd(
            *tensor_handle_to_tensor_pointer(A), full_matrices, compute_uv, pointer_to_optional<c10::string_view>(driver)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__pdist_backward(AtenTensorHandle grad, AtenTensorHandle self, double p, AtenTensorHandle pdist, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_pdist_backward(
            *tensor_handle_to_tensor_pointer(grad), *tensor_handle_to_tensor_pointer(self), p, *tensor_handle_to_tensor_pointer(pdist)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__pdist_forward(AtenTensorHandle self, double p, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_pdist_forward(
            *tensor_handle_to_tensor_pointer(self), p
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__scaled_dot_product_efficient_attention(AtenTensorHandle query, AtenTensorHandle key, AtenTensorHandle value, AtenTensorHandle* attn_bias, int32_t compute_log_sumexp, double dropout_p, int32_t is_causal, double* scale, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_scaled_dot_product_efficient_attention(
            *tensor_handle_to_tensor_pointer(query), *tensor_handle_to_tensor_pointer(key), *tensor_handle_to_tensor_pointer(value), pointer_to_optional<at::Tensor>(attn_bias), compute_log_sumexp, dropout_p, is_causal, pointer_to_optional<double>(scale)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
        *ret3 = new_tensor_handle(std::move(std::get<3>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__scaled_dot_product_efficient_attention_backward(AtenTensorHandle grad_out_, AtenTensorHandle query, AtenTensorHandle key, AtenTensorHandle value, AtenTensorHandle attn_bias, AtenTensorHandle out, AtenTensorHandle logsumexp, AtenTensorHandle philox_seed, AtenTensorHandle philox_offset, double dropout_p, const int32_t* grad_input_mask, int64_t grad_input_mask_len_, int32_t is_causal, double* scale, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_scaled_dot_product_efficient_attention_backward(
            *tensor_handle_to_tensor_pointer(grad_out_), *tensor_handle_to_tensor_pointer(query), *tensor_handle_to_tensor_pointer(key), *tensor_handle_to_tensor_pointer(value), *tensor_handle_to_tensor_pointer(attn_bias), *tensor_handle_to_tensor_pointer(out), *tensor_handle_to_tensor_pointer(logsumexp), *tensor_handle_to_tensor_pointer(philox_seed), *tensor_handle_to_tensor_pointer(philox_offset), dropout_p, pointer_to_list<4>(grad_input_mask), is_causal, pointer_to_optional<double>(scale)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
        *ret3 = new_tensor_handle(std::move(std::get<3>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__scaled_dot_product_flash_attention(AtenTensorHandle query, AtenTensorHandle key, AtenTensorHandle value, double dropout_p, int32_t is_causal, int32_t return_debug_mask, double* scale, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3, int64_t* ret4, int64_t* ret5, AtenTensorHandle* ret6, AtenTensorHandle* ret7, AtenTensorHandle* ret8) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_scaled_dot_product_flash_attention(
            *tensor_handle_to_tensor_pointer(query), *tensor_handle_to_tensor_pointer(key), *tensor_handle_to_tensor_pointer(value), dropout_p, is_causal, return_debug_mask, pointer_to_optional<double>(scale)
        );
        if (ret0) { *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));; }
        if (ret1) { *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));; }
        if (ret2) { *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));; }
        if (ret3) { *ret3 = new_tensor_handle(std::move(std::get<3>(tmp_result)));; }
        if (ret4) { *ret4 = std::get<4>(tmp_result).expect_int(); }
        if (ret5) { *ret5 = std::get<5>(tmp_result).expect_int(); }
        if (ret6) { *ret6 = new_tensor_handle(std::move(std::get<6>(tmp_result)));; }
        if (ret7) { *ret7 = new_tensor_handle(std::move(std::get<7>(tmp_result)));; }
        if (ret8) { *ret8 = new_tensor_handle(std::move(std::get<8>(tmp_result)));; }
    });
}


AOTITorchError aoti_torch_cuda__scaled_dot_product_flash_attention_backward(AtenTensorHandle grad_out, AtenTensorHandle query, AtenTensorHandle key, AtenTensorHandle value, AtenTensorHandle out, AtenTensorHandle logsumexp, AtenTensorHandle cum_seq_q, AtenTensorHandle cum_seq_k, int64_t max_q, int64_t max_k, double dropout_p, int32_t is_causal, AtenTensorHandle philox_seed, AtenTensorHandle philox_offset, double* scale, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_scaled_dot_product_flash_attention_backward_symint(
            *tensor_handle_to_tensor_pointer(grad_out), *tensor_handle_to_tensor_pointer(query), *tensor_handle_to_tensor_pointer(key), *tensor_handle_to_tensor_pointer(value), *tensor_handle_to_tensor_pointer(out), *tensor_handle_to_tensor_pointer(logsumexp), *tensor_handle_to_tensor_pointer(cum_seq_q), *tensor_handle_to_tensor_pointer(cum_seq_k), max_q, max_k, dropout_p, is_causal, *tensor_handle_to_tensor_pointer(philox_seed), *tensor_handle_to_tensor_pointer(philox_offset), pointer_to_optional<double>(scale)
        );
        if (ret0) { *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));; }
        if (ret1) { *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));; }
        if (ret2) { *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));; }
    });
}


AOTITorchError aoti_torch_cuda__scaled_mm(AtenTensorHandle self, AtenTensorHandle mat2, AtenTensorHandle* bias, int32_t* out_dtype, AtenTensorHandle* scale_a, AtenTensorHandle* scale_b, AtenTensorHandle* scale_result, int32_t use_fast_accum, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_scaled_mm(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(mat2), pointer_to_optional<at::Tensor>(bias), pointer_to_optional<c10::ScalarType>(out_dtype), pointer_to_optional<at::Tensor>(scale_a), pointer_to_optional<at::Tensor>(scale_b), pointer_to_optional<at::Tensor>(scale_result), use_fast_accum
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__segment_reduce_backward(AtenTensorHandle grad, AtenTensorHandle output, AtenTensorHandle data, const char* reduce, AtenTensorHandle* lengths, AtenTensorHandle* offsets, int64_t axis, double* initial, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_segment_reduce_backward(
            *tensor_handle_to_tensor_pointer(grad), *tensor_handle_to_tensor_pointer(output), *tensor_handle_to_tensor_pointer(data), reduce, pointer_to_optional<at::Tensor>(lengths), pointer_to_optional<at::Tensor>(offsets), axis, pointer_to_optional<c10::Scalar>(initial)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__thnn_fused_lstm_cell(AtenTensorHandle input_gates, AtenTensorHandle hidden_gates, AtenTensorHandle cx, AtenTensorHandle* input_bias, AtenTensorHandle* hidden_bias, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_thnn_fused_lstm_cell(
            *tensor_handle_to_tensor_pointer(input_gates), *tensor_handle_to_tensor_pointer(hidden_gates), *tensor_handle_to_tensor_pointer(cx), pointer_to_optional<at::Tensor>(input_bias), pointer_to_optional<at::Tensor>(hidden_bias)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda__to_sparse(AtenTensorHandle self, int32_t* layout, const int64_t** blocksize, int64_t blocksize_len_, int64_t* dense_dim, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::_to_sparse(
            *tensor_handle_to_tensor_pointer(self), pointer_to_optional<c10::Layout>(layout), pointer_to_optional_list<int64_t>(blocksize, blocksize_len_), pointer_to_optional<int64_t>(dense_dim)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda__trilinear(AtenTensorHandle i1, AtenTensorHandle i2, AtenTensorHandle i3, const int64_t* expand1, int64_t expand1_len_, const int64_t* expand2, int64_t expand2_len_, const int64_t* expand3, int64_t expand3_len_, const int64_t* sumdim, int64_t sumdim_len_, int64_t unroll_dim, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautogradnonfunctional::_trilinear(
            *tensor_handle_to_tensor_pointer(i1), *tensor_handle_to_tensor_pointer(i2), *tensor_handle_to_tensor_pointer(i3), pointer_to_list<int64_t>(expand1, expand1_len_), pointer_to_list<int64_t>(expand2, expand2_len_), pointer_to_list<int64_t>(expand3, expand3_len_), pointer_to_list<int64_t>(sumdim, sumdim_len_), unroll_dim
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_adaptive_max_pool2d(AtenTensorHandle self, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::adaptive_max_pool2d(
            *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(output_size, output_size_len_)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_adaptive_max_pool2d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, AtenTensorHandle indices, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::adaptive_max_pool2d_backward(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(indices)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_adaptive_max_pool3d(AtenTensorHandle self, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::adaptive_max_pool3d(
            *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(output_size, output_size_len_)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_adaptive_max_pool3d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, AtenTensorHandle indices, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::adaptive_max_pool3d_backward(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(indices)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_addbmm(AtenTensorHandle self, AtenTensorHandle batch1, AtenTensorHandle batch2, double beta, double alpha, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::addbmm(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(batch1), *tensor_handle_to_tensor_pointer(batch2), beta, alpha
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_addmm_out(AtenTensorHandle out, AtenTensorHandle self, AtenTensorHandle mat1, AtenTensorHandle mat2, double beta, double alpha) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        at::cuda::addmm_out(
            *tensor_handle_to_tensor_pointer(out), *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(mat1), *tensor_handle_to_tensor_pointer(mat2), beta, alpha
        );
    });
}


AOTITorchError aoti_torch_cuda_addmv(AtenTensorHandle self, AtenTensorHandle mat, AtenTensorHandle vec, double beta, double alpha, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::addmv(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(mat), *tensor_handle_to_tensor_pointer(vec), beta, alpha
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_angle(AtenTensorHandle self, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::angle(
            *tensor_handle_to_tensor_pointer(self)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_avg_pool2d(AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, int32_t ceil_mode, int32_t count_include_pad, int64_t* divisor_override, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::avg_pool2d(
            *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(kernel_size, kernel_size_len_), pointer_to_list<int64_t>(stride, stride_len_), pointer_to_list<int64_t>(padding, padding_len_), ceil_mode, count_include_pad, pointer_to_optional<int64_t>(divisor_override)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_avg_pool2d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, int32_t ceil_mode, int32_t count_include_pad, int64_t* divisor_override, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::avg_pool2d_backward(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(kernel_size, kernel_size_len_), pointer_to_list<int64_t>(stride, stride_len_), pointer_to_list<int64_t>(padding, padding_len_), ceil_mode, count_include_pad, pointer_to_optional<int64_t>(divisor_override)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_avg_pool3d(AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, int32_t ceil_mode, int32_t count_include_pad, int64_t* divisor_override, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::avg_pool3d(
            *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(kernel_size, kernel_size_len_), pointer_to_list<int64_t>(stride, stride_len_), pointer_to_list<int64_t>(padding, padding_len_), ceil_mode, count_include_pad, pointer_to_optional<int64_t>(divisor_override)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_avg_pool3d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, int32_t ceil_mode, int32_t count_include_pad, int64_t* divisor_override, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::avg_pool3d_backward(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(kernel_size, kernel_size_len_), pointer_to_list<int64_t>(stride, stride_len_), pointer_to_list<int64_t>(padding, padding_len_), ceil_mode, count_include_pad, pointer_to_optional<int64_t>(divisor_override)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_bmm_out(AtenTensorHandle out, AtenTensorHandle self, AtenTensorHandle mat2) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        at::cuda::bmm_out(
            *tensor_handle_to_tensor_pointer(out), *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(mat2)
        );
    });
}


AOTITorchError aoti_torch_cuda_bucketize_Tensor(AtenTensorHandle self, AtenTensorHandle boundaries, int32_t out_int32, int32_t right, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::bucketize(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(boundaries), out_int32, right
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_cat(const AtenTensorHandle* tensors, int64_t tensors_len_, int64_t dim, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::cat(
            pointer_to_list<at::Tensor>(tensors, tensors_len_), dim
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_cholesky_inverse(AtenTensorHandle self, int32_t upper, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::cholesky_inverse(
            *tensor_handle_to_tensor_pointer(self), upper
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_cholesky_solve(AtenTensorHandle self, AtenTensorHandle input2, int32_t upper, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::cholesky_solve(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(input2), upper
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_convolution(AtenTensorHandle input, AtenTensorHandle weight, AtenTensorHandle* bias, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, const int64_t* dilation, int64_t dilation_len_, int32_t transposed, const int64_t* output_padding, int64_t output_padding_len_, int64_t groups, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::convolution_symint(
            *tensor_handle_to_tensor_pointer(input), *tensor_handle_to_tensor_pointer(weight), pointer_to_optional<at::Tensor>(bias), pointer_to_list<c10::SymInt>(stride, stride_len_), pointer_to_list<c10::SymInt>(padding, padding_len_), pointer_to_list<c10::SymInt>(dilation, dilation_len_), transposed, pointer_to_list<c10::SymInt>(output_padding, output_padding_len_), groups
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_convolution_backward(AtenTensorHandle grad_output, AtenTensorHandle input, AtenTensorHandle weight, const int64_t** bias_sizes, int64_t bias_sizes_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, const int64_t* dilation, int64_t dilation_len_, int32_t transposed, const int64_t* output_padding, int64_t output_padding_len_, int64_t groups, const int32_t* output_mask, int64_t output_mask_len_, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::convolution_backward_symint(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(input), *tensor_handle_to_tensor_pointer(weight), pointer_to_optional_list<c10::SymInt>(bias_sizes, bias_sizes_len_), pointer_to_list<c10::SymInt>(stride, stride_len_), pointer_to_list<c10::SymInt>(padding, padding_len_), pointer_to_list<c10::SymInt>(dilation, dilation_len_), transposed, pointer_to_list<c10::SymInt>(output_padding, output_padding_len_), groups, pointer_to_list<3>(output_mask)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_cummax(AtenTensorHandle self, int64_t dim, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::cummax(
            *tensor_handle_to_tensor_pointer(self), dim
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_cummin(AtenTensorHandle self, int64_t dim, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::cummin(
            *tensor_handle_to_tensor_pointer(self), dim
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_cumprod(AtenTensorHandle self, int64_t dim, int32_t* dtype, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::cumprod(
            *tensor_handle_to_tensor_pointer(self), dim, pointer_to_optional<c10::ScalarType>(dtype)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_cumsum(AtenTensorHandle self, int64_t dim, int32_t* dtype, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::cumsum(
            *tensor_handle_to_tensor_pointer(self), dim, pointer_to_optional<c10::ScalarType>(dtype)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_fractional_max_pool2d(AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle random_samples, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::fractional_max_pool2d(
            *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(kernel_size, kernel_size_len_), pointer_to_list<int64_t>(output_size, output_size_len_), *tensor_handle_to_tensor_pointer(random_samples)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_fractional_max_pool2d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle indices, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::fractional_max_pool2d_backward(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(kernel_size, kernel_size_len_), pointer_to_list<int64_t>(output_size, output_size_len_), *tensor_handle_to_tensor_pointer(indices)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_fractional_max_pool3d(AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle random_samples, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::fractional_max_pool3d(
            *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(kernel_size, kernel_size_len_), pointer_to_list<int64_t>(output_size, output_size_len_), *tensor_handle_to_tensor_pointer(random_samples)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_fractional_max_pool3d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle indices, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::fractional_max_pool3d_backward(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(kernel_size, kernel_size_len_), pointer_to_list<int64_t>(output_size, output_size_len_), *tensor_handle_to_tensor_pointer(indices)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_gcd(AtenTensorHandle self, AtenTensorHandle other, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::gcd(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(other)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_geqrf(AtenTensorHandle self, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::geqrf(
            *tensor_handle_to_tensor_pointer(self)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_grid_sampler_2d_backward(AtenTensorHandle grad_output, AtenTensorHandle input, AtenTensorHandle grid, int64_t interpolation_mode, int64_t padding_mode, int32_t align_corners, const int32_t* output_mask, int64_t output_mask_len_, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::grid_sampler_2d_backward(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(input), *tensor_handle_to_tensor_pointer(grid), interpolation_mode, padding_mode, align_corners, pointer_to_list<2>(output_mask)
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_histc(AtenTensorHandle self, int64_t bins, double min, double max, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::histc(
            *tensor_handle_to_tensor_pointer(self), bins, min, max
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_index_reduce(AtenTensorHandle self, int64_t dim, AtenTensorHandle index, AtenTensorHandle source, const char* reduce, int32_t include_self, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::index_reduce(
            *tensor_handle_to_tensor_pointer(self), dim, *tensor_handle_to_tensor_pointer(index), *tensor_handle_to_tensor_pointer(source), reduce, include_self
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_kthvalue(AtenTensorHandle self, int64_t k, int64_t dim, int32_t keepdim, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::kthvalue(
            *tensor_handle_to_tensor_pointer(self), k, dim, keepdim
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_linalg_cholesky_ex(AtenTensorHandle self, int32_t upper, int32_t check_errors, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::linalg_cholesky_ex(
            *tensor_handle_to_tensor_pointer(self), upper, check_errors
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_linalg_householder_product(AtenTensorHandle input, AtenTensorHandle tau, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::linalg_householder_product(
            *tensor_handle_to_tensor_pointer(input), *tensor_handle_to_tensor_pointer(tau)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_linalg_inv_ex(AtenTensorHandle A, int32_t check_errors, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::linalg_inv_ex(
            *tensor_handle_to_tensor_pointer(A), check_errors
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_linalg_ldl_factor_ex(AtenTensorHandle self, int32_t hermitian, int32_t check_errors, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::linalg_ldl_factor_ex(
            *tensor_handle_to_tensor_pointer(self), hermitian, check_errors
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_linalg_ldl_solve(AtenTensorHandle LD, AtenTensorHandle pivots, AtenTensorHandle B, int32_t hermitian, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::linalg_ldl_solve(
            *tensor_handle_to_tensor_pointer(LD), *tensor_handle_to_tensor_pointer(pivots), *tensor_handle_to_tensor_pointer(B), hermitian
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_linalg_lu(AtenTensorHandle A, int32_t pivot, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::linalg_lu(
            *tensor_handle_to_tensor_pointer(A), pivot
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_linalg_lu_factor_ex(AtenTensorHandle A, int32_t pivot, int32_t check_errors, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::linalg_lu_factor_ex(
            *tensor_handle_to_tensor_pointer(A), pivot, check_errors
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_linalg_lu_solve(AtenTensorHandle LU, AtenTensorHandle pivots, AtenTensorHandle B, int32_t left, int32_t adjoint, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::linalg_lu_solve(
            *tensor_handle_to_tensor_pointer(LU), *tensor_handle_to_tensor_pointer(pivots), *tensor_handle_to_tensor_pointer(B), left, adjoint
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_linalg_matrix_exp(AtenTensorHandle self, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::linalg_matrix_exp(
            *tensor_handle_to_tensor_pointer(self)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_linalg_pinv_atol_rtol_tensor(AtenTensorHandle self, AtenTensorHandle* atol, AtenTensorHandle* rtol, int32_t hermitian, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautogradnonfunctional::linalg_pinv(
            *tensor_handle_to_tensor_pointer(self), pointer_to_optional<at::Tensor>(atol), pointer_to_optional<at::Tensor>(rtol), hermitian
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_linalg_qr(AtenTensorHandle A, const char* mode, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::linalg_qr(
            *tensor_handle_to_tensor_pointer(A), mode
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_linalg_solve_triangular(AtenTensorHandle self, AtenTensorHandle B, int32_t upper, int32_t left, int32_t unitriangular, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::linalg_solve_triangular(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(B), upper, left, unitriangular
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_logcumsumexp(AtenTensorHandle self, int64_t dim, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::logcumsumexp(
            *tensor_handle_to_tensor_pointer(self), dim
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_lu_unpack(AtenTensorHandle LU_data, AtenTensorHandle LU_pivots, int32_t unpack_data, int32_t unpack_pivots, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::lu_unpack(
            *tensor_handle_to_tensor_pointer(LU_data), *tensor_handle_to_tensor_pointer(LU_pivots), unpack_data, unpack_pivots
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
        *ret2 = new_tensor_handle(std::move(std::get<2>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_masked_scatter(AtenTensorHandle self, AtenTensorHandle mask, AtenTensorHandle source, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::masked_scatter(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(mask), *tensor_handle_to_tensor_pointer(source)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_masked_scatter_backward(AtenTensorHandle grad_output, AtenTensorHandle mask, const int64_t* sizes, int64_t sizes_len_, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::masked_scatter_backward_symint(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(mask), pointer_to_list<c10::SymInt>(sizes, sizes_len_)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_max_pool2d_with_indices(AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, const int64_t* dilation, int64_t dilation_len_, int32_t ceil_mode, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::max_pool2d_with_indices(
            *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(kernel_size, kernel_size_len_), pointer_to_list<int64_t>(stride, stride_len_), pointer_to_list<int64_t>(padding, padding_len_), pointer_to_list<int64_t>(dilation, dilation_len_), ceil_mode
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_max_pool2d_with_indices_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, const int64_t* dilation, int64_t dilation_len_, int32_t ceil_mode, AtenTensorHandle indices, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::max_pool2d_with_indices_backward(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(kernel_size, kernel_size_len_), pointer_to_list<int64_t>(stride, stride_len_), pointer_to_list<int64_t>(padding, padding_len_), pointer_to_list<int64_t>(dilation, dilation_len_), ceil_mode, *tensor_handle_to_tensor_pointer(indices)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_max_pool3d_with_indices(AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, const int64_t* dilation, int64_t dilation_len_, int32_t ceil_mode, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::max_pool3d_with_indices(
            *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(kernel_size, kernel_size_len_), pointer_to_list<int64_t>(stride, stride_len_), pointer_to_list<int64_t>(padding, padding_len_), pointer_to_list<int64_t>(dilation, dilation_len_), ceil_mode
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_max_pool3d_with_indices_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, const int64_t* dilation, int64_t dilation_len_, int32_t ceil_mode, AtenTensorHandle indices, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::max_pool3d_with_indices_backward(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(self), pointer_to_list<int64_t>(kernel_size, kernel_size_len_), pointer_to_list<int64_t>(stride, stride_len_), pointer_to_list<int64_t>(padding, padding_len_), pointer_to_list<int64_t>(dilation, dilation_len_), ceil_mode, *tensor_handle_to_tensor_pointer(indices)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_max_unpool2d(AtenTensorHandle self, AtenTensorHandle indices, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::max_unpool2d_symint(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(indices), pointer_to_list<c10::SymInt>(output_size, output_size_len_)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_max_unpool3d(AtenTensorHandle self, AtenTensorHandle indices, const int64_t* output_size, int64_t output_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::max_unpool3d_symint(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(indices), pointer_to_list<c10::SymInt>(output_size, output_size_len_), pointer_to_list<int64_t>(stride, stride_len_), pointer_to_list<int64_t>(padding, padding_len_)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_median(AtenTensorHandle self, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::median(
            *tensor_handle_to_tensor_pointer(self)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_mm_out(AtenTensorHandle out, AtenTensorHandle self, AtenTensorHandle mat2) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        at::cuda::mm_out(
            *tensor_handle_to_tensor_pointer(out), *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(mat2)
        );
    });
}


AOTITorchError aoti_torch_cuda_mode(AtenTensorHandle self, int64_t dim, int32_t keepdim, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::mode(
            *tensor_handle_to_tensor_pointer(self), dim, keepdim
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_mul_Scalar(AtenTensorHandle self, double other, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::mul(
            *tensor_handle_to_tensor_pointer(self), other
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_nanmedian(AtenTensorHandle self, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::nanmedian(
            *tensor_handle_to_tensor_pointer(self)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_nonzero(AtenTensorHandle self, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::nonzero(
            *tensor_handle_to_tensor_pointer(self)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_ormqr(AtenTensorHandle self, AtenTensorHandle input2, AtenTensorHandle input3, int32_t left, int32_t transpose, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::ormqr(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(input2), *tensor_handle_to_tensor_pointer(input3), left, transpose
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_rand(const int64_t* size, int64_t size_len_, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::rand_symint(
            pointer_to_list<c10::SymInt>(size, size_len_), pointer_to_optional<c10::ScalarType>(dtype), pointer_to_optional<c10::Layout>(layout), pointer_to_optional_device(device, device_index_), pointer_to_optional<bool>(pin_memory)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_randint(int64_t high, const int64_t* size, int64_t size_len_, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::randint_symint(
            high, pointer_to_list<c10::SymInt>(size, size_len_), pointer_to_optional<c10::ScalarType>(dtype), pointer_to_optional<c10::Layout>(layout), pointer_to_optional_device(device, device_index_), pointer_to_optional<bool>(pin_memory)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_randn(const int64_t* size, int64_t size_len_, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::randn_symint(
            pointer_to_list<c10::SymInt>(size, size_len_), pointer_to_optional<c10::ScalarType>(dtype), pointer_to_optional<c10::Layout>(layout), pointer_to_optional_device(device, device_index_), pointer_to_optional<bool>(pin_memory)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_randperm(int64_t n, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::randperm_symint(
            n, pointer_to_optional<c10::ScalarType>(dtype), pointer_to_optional<c10::Layout>(layout), pointer_to_optional_device(device, device_index_), pointer_to_optional<bool>(pin_memory)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_repeat_interleave_Tensor(AtenTensorHandle repeats, int64_t* output_size, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::repeat_interleave_symint(
            *tensor_handle_to_tensor_pointer(repeats), pointer_to_optional<c10::SymInt>(output_size)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_replication_pad1d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* padding, int64_t padding_len_, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::replication_pad1d_backward_symint(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(self), pointer_to_list<c10::SymInt>(padding, padding_len_)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_replication_pad2d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* padding, int64_t padding_len_, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::replication_pad2d_backward_symint(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(self), pointer_to_list<c10::SymInt>(padding, padding_len_)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_resize_(AtenTensorHandle self, const int64_t* size, int64_t size_len_, int32_t* memory_format, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::resize__symint(
            *tensor_handle_to_tensor_pointer(self), pointer_to_list<c10::SymInt>(size, size_len_), pointer_to_optional<c10::MemoryFormat>(memory_format)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_resize_as_(AtenTensorHandle self, AtenTensorHandle the_template, int32_t* memory_format, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::resize_as_(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(the_template), pointer_to_optional<c10::MemoryFormat>(memory_format)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_scatter_src_out(AtenTensorHandle out, AtenTensorHandle self, int64_t dim, AtenTensorHandle index, AtenTensorHandle src) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        at::cuda::scatter_out(
            *tensor_handle_to_tensor_pointer(out), *tensor_handle_to_tensor_pointer(self), dim, *tensor_handle_to_tensor_pointer(index), *tensor_handle_to_tensor_pointer(src)
        );
    });
}


AOTITorchError aoti_torch_cuda_scatter_reduce_two_out(AtenTensorHandle out, AtenTensorHandle self, int64_t dim, AtenTensorHandle index, AtenTensorHandle src, const char* reduce, int32_t include_self) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        at::cuda::scatter_reduce_out(
            *tensor_handle_to_tensor_pointer(out), *tensor_handle_to_tensor_pointer(self), dim, *tensor_handle_to_tensor_pointer(index), *tensor_handle_to_tensor_pointer(src), reduce, include_self
        );
    });
}


AOTITorchError aoti_torch_cuda_segment_reduce(AtenTensorHandle data, const char* reduce, AtenTensorHandle* lengths, AtenTensorHandle* indices, AtenTensorHandle* offsets, int64_t axis, int32_t unsafe, double* initial, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::segment_reduce(
            *tensor_handle_to_tensor_pointer(data), reduce, pointer_to_optional<at::Tensor>(lengths), pointer_to_optional<at::Tensor>(indices), pointer_to_optional<at::Tensor>(offsets), axis, unsafe, pointer_to_optional<c10::Scalar>(initial)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_soft_margin_loss_backward(AtenTensorHandle grad_output, AtenTensorHandle self, AtenTensorHandle target, int64_t reduction, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::soft_margin_loss_backward(
            *tensor_handle_to_tensor_pointer(grad_output), *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(target), reduction
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_sort(AtenTensorHandle self, int64_t dim, int32_t descending, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::sort(
            *tensor_handle_to_tensor_pointer(self), dim, descending
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_topk(AtenTensorHandle self, int64_t k, int64_t dim, int32_t largest, int32_t sorted, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::topk_symint(
            *tensor_handle_to_tensor_pointer(self), k, dim, largest, sorted
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_triangular_solve(AtenTensorHandle self, AtenTensorHandle A, int32_t upper, int32_t transpose, int32_t unitriangular, AtenTensorHandle* ret0, AtenTensorHandle* ret1) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::triangular_solve(
            *tensor_handle_to_tensor_pointer(self), *tensor_handle_to_tensor_pointer(A), upper, transpose, unitriangular
        );
        *ret0 = new_tensor_handle(std::move(std::get<0>(tmp_result)));;
        *ret1 = new_tensor_handle(std::move(std::get<1>(tmp_result)));;
    });
}


AOTITorchError aoti_torch_cuda_upsample_bicubic2d_backward(AtenTensorHandle grad_output, const int64_t* output_size, int64_t output_size_len_, const int64_t* input_size, int64_t input_size_len_, int32_t align_corners, double* scales_h, double* scales_w, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::upsample_bicubic2d_backward_symint(
            *tensor_handle_to_tensor_pointer(grad_output), pointer_to_list<c10::SymInt>(output_size, output_size_len_), pointer_to_list<c10::SymInt>(input_size, input_size_len_), align_corners, pointer_to_optional<double>(scales_h), pointer_to_optional<double>(scales_w)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_upsample_linear1d_backward(AtenTensorHandle grad_output, const int64_t* output_size, int64_t output_size_len_, const int64_t* input_size, int64_t input_size_len_, int32_t align_corners, double* scales, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::upsample_linear1d_backward_symint(
            *tensor_handle_to_tensor_pointer(grad_output), pointer_to_list<c10::SymInt>(output_size, output_size_len_), pointer_to_list<c10::SymInt>(input_size, input_size_len_), align_corners, pointer_to_optional<double>(scales)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_upsample_trilinear3d_backward(AtenTensorHandle grad_output, const int64_t* output_size, int64_t output_size_len_, const int64_t* input_size, int64_t input_size_len_, int32_t align_corners, double* scales_d, double* scales_h, double* scales_w, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::upsample_trilinear3d_backward_symint(
            *tensor_handle_to_tensor_pointer(grad_output), pointer_to_list<c10::SymInt>(output_size, output_size_len_), pointer_to_list<c10::SymInt>(input_size, input_size_len_), align_corners, pointer_to_optional<double>(scales_d), pointer_to_optional<double>(scales_h), pointer_to_optional<double>(scales_w)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_view_dtype(AtenTensorHandle self, int32_t dtype, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::compositeexplicitautograd::view(
            *tensor_handle_to_tensor_pointer(self), static_cast<c10::ScalarType>(dtype)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_view_as_complex(AtenTensorHandle self, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::view_as_complex(
            *tensor_handle_to_tensor_pointer(self)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}


AOTITorchError aoti_torch_cuda_view_as_real(AtenTensorHandle self, AtenTensorHandle* ret0) {
    AOTI_TORCH_CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto tmp_result = at::cuda::view_as_real(
            *tensor_handle_to_tensor_pointer(self)
        );
        *ret0 = new_tensor_handle(std::move(tmp_result));;
    });
}
